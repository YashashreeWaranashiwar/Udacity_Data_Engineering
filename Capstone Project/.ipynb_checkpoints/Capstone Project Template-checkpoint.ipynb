{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n",
    "sqlContext.setConf(\"spark.sql.autoBroadcastJoinThreshold\", \"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "The aim of this project is to gather data from various sources and create fact and dimension tables which gives information about immigration in United States.\n",
    "As end result fact table will give information about immigration per city in united state. Spark was chosen as tool to do this anaylsis.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "##### 1. I94 Immigration Data\n",
    "This data comes from the US National Tourism and Trade Office. This data consists of information like origin country, destination city, year and month of departure, type of visa.\n",
    "\n",
    "##### 2. World Temperature Data\n",
    "This dataset came from Kaggle. This data consists of information about date, temperature, city, country, longitude and latitude\n",
    "\n",
    "##### 3. U.S. City Demographic Data\n",
    "This data comes from OpenSoft.It consists of demographic information about population, us cities and states.\n",
    "\n",
    "##### 4. I94CIT\n",
    "This csv file consists of information about valid codes of countries.\n",
    "\n",
    "##### 5. I94PORT_CODES\n",
    "This csv consists of information about airport codes and city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_immigration = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|               i94yr|\n",
      "+-------+--------------------+\n",
      "|  count|             3096313|\n",
      "|   mean|              2016.0|\n",
      "| stddev|4.282829613261096...|\n",
      "|    min|              2016.0|\n",
      "|    max|              2016.0|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.describe([\"i94yr\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              year|\n",
      "+-------+------------------+\n",
      "|  count|           8599212|\n",
      "|   mean|1907.3451412757354|\n",
      "| stddev| 65.59948928964944|\n",
      "|    min|              1743|\n",
      "|    max|              2013|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp = df_temp.withColumn(\"year\",year(df_temp[\"dt\"]))\n",
    "df_temp.describe([\"year\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read valid i94cit codes from csv and create temporary view i94cit_valid\n",
    "fname = 'I94CIT.csv'\n",
    "df_i94cit_valid = spark.read.csv(fname,sep=\";\",header = True)\n",
    "df_i94cit_valid.createOrReplaceTempView(\"i94cit_valid\")\n",
    "\n",
    "# Read valid i94port codes from csv and create temporary view i94port_valid\n",
    "fname = 'I94PORT_CODE.csv'\n",
    "df_i94port_valid = spark.read.csv(fname,sep=\"\\t\",header = True)\n",
    "df_i94port_valid.createOrReplaceTempView(\"i94port_valid\")\n",
    "\n",
    "# Read immigration data and create temporary view immigration_data\n",
    "df_immigration =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_immigration.createOrReplaceTempView(\"immigration_data\")\n",
    "\n",
    "# Read us demographic data and create temporary view us_city_demo\n",
    "fname = 'us-cities-demographics.csv'\n",
    "df_us_city_demo = spark.read.csv(fname,sep=\";\",header = True)\n",
    "\n",
    "# Read GlobalLandTemperaturesByCity and create temporary view tempreture_data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = spark.read.csv(fname,header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "##### 1. Immigration Data - \n",
    "###### Findings : \n",
    "-  There might be invalid country codes(I94CIT) or port codes (I94PORT) in immigration data.\n",
    "-  Since only specific columns were considered for further analysis, duplicates were idenified.\n",
    "\n",
    "###### Resolution : \n",
    "- The invalid codes were removed by joining immigration data with valid I94_CODE and I94CIT.\n",
    "- The duplicates were dropped.\n",
    "\n",
    "##### 2. Temperature Data -\n",
    "###### Findings : \n",
    "- There are some records where AverageTemperture column contains null values. \n",
    "\n",
    "###### Resolution : \n",
    "- These null values in AverageTemperture column were filtered out.\n",
    "- Also filter was applied on Country column as United States and Year as 2013.\n",
    "\n",
    "###### Assumption\n",
    "- The temperture data is from year 1743 to 2013. And immigration data is for year 2016. So filter was applied to temperture data for year 2013(most recent temperature) and assuption was made that average temperature for year 2016 will be same as 2013.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating temporary view for US City Info which consists of information about US State, US State Code and US City\n",
    "df_city = df_us_city_demo.select(col(\"state code\").alias(\"us_state_code\"),col(\"state\").alias(\"us_state\"),col(\"city\").alias(\"us_city\")).dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Joining immigration data with I94CIT and 94PORT_CODES to filter out invalid data\n",
    "\n",
    "Immigration_table = spark.sql(\"\"\"\n",
    "    SELECT distinct \n",
    "           im.cicid as cicid\n",
    "          ,im.i94yr as year\n",
    "          ,im.i94mon as month\n",
    "          ,cit.i94res as origin_country\n",
    "          ,im.i94Port as destination_airport_code\n",
    "          ,Case \n",
    "            when port.I94Port like '%,%' then Substring(port.I94Port,1, Position(',' in port.I94Port )-1 ) \n",
    "            else port.I94Port \n",
    "            end as destination_us_city\n",
    "    FROM immigration_data im\n",
    "      inner join i94cit_valid cit\n",
    "       on im.i94cit = cit.i94cit\n",
    "      inner join i94port_valid port\n",
    "       on im.i94port = port.i94port_code\n",
    "      \"\"\")\n",
    "\n",
    "df_Immigration_table = df_Immigration_table.select(\"cicid\",col(\"year\").cast(\"integer\"),col(\"month\").cast(\"integer\"),\"origin_country\",\"destination_airport_code\",\"destination_us_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filtering AverageTemperature column having null values\n",
    "df_temp_cleanse = df_temp.filter(df_temp.AverageTemperature != 'NaN') \n",
    "\n",
    "# Retrieving only US tempreture data\n",
    "df_temp_us= df_temp_cleanse.filter(df_temp_cleanse.Country == \"United States\")\\\n",
    ".filter(year(df_temp_cleanse[\"dt\"]) ==2013)\\\n",
    ".withColumn(\"month\", month(df_temp_cleanse[\"dt\"]))\\\n",
    ".withColumn(\"year\", year(df_temp_cleanse[\"dt\"]))\n",
    "\n",
    "# selecting specific columns from tempreture dataframe\n",
    "df_temperature_city = df_temp_us.select(col(\"year\").cast(\"integer\"),col(\"month\").cast(\"integer\"),round('AverageTemperature', 2).alias('AverageTemperature'),col(\"city\").alias(\"temp_city\"),\"country\").dropDuplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Columns like percent_Male_Population, percent_Female_Population, percent_veterans, percent_foreigners, percent_race derived with the help of existsing columns in dataframe\n",
    "\n",
    "us_demographic_info = df_us_city_demo\\\n",
    ".withColumn(\"percent_Male_Population\",round(df_us_city_demo[\"Male Population\"]/df_us_city_demo[\"Total Population\"]*100,2))\\\n",
    ".withColumn(\"percent_Female_Population\",round(df_us_city_demo[\"Female Population\"]/df_us_city_demo[\"Total Population\"]*100,2))\\\n",
    ".withColumn(\"percent_veterans\",round(df_us_city_demo[\"Number of Veterans\"]/df_us_city_demo[\"Total Population\"]*100,2))\\\n",
    ".withColumn(\"percent_foreigners\",round(df_us_city_demo[\"Foreign-born\"]/df_us_city_demo[\"Total Population\"]*100,2))\\\n",
    ".withColumn(\"percent_race\",round(df_us_city_demo[\"count\"]/df_us_city_demo[\"Total Population\"]*100,2))\\\n",
    ".withColumn(\"Median_Age\",col(\"Median Age\").cast(\"float\"))\n",
    "\n",
    "# Unnecessary columns were removed\n",
    "us_demographic_info = us_demographic_info.select(\"city\",\"Median_Age\",\"percent_Male_Population\",\"percent_Female_Population\",\"percent_veterans\",\"percent_foreigners\",\"percent_race\",\"Race\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pivote table based on Race column\n",
    "pivot_demographic_info = us_demographic_info.groupBy(\"City\",\"median_age\",\"percent_Male_Population\",\\\n",
    "                                    \"percent_Female_Population\",\"percent_veterans\",\\\n",
    "                                    \"percent_foreigners\").pivot(\"Race\").avg(\"percent_race\")\n",
    "\n",
    "# Renaming columns in pivoted dataframe\n",
    "pivot_demographic_info = pivot_demographic_info.select(\"City\",\"median_age\",\"percent_Male_Population\",\\\n",
    "                                                       \"percent_Female_Population\",\"percent_veterans\",\\\n",
    "                                                       \"percent_foreigners\",\\\n",
    "                                                       col(\"American Indian and Alaska Native\").alias(\"natives\"),\\\n",
    "                                                       col(\"Asian\"),col(\"Black or African-American\").alias(\"Black\"),\\\n",
    "                                                       col(\"Hispanic or Latino\").alias(\"hispanic_or_latino\"),\\\n",
    "                                                       \"White\")\n",
    "\n",
    "df_demographic_info = pivot_demographic_info.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "- From source data following 4 dimension tables are created. \n",
    "\n",
    "    1. Dim_Temperature   -  This table consists of Temperature information of US city\n",
    "    2. Dim_Immigration - This table gives information about country of origin, year and month of immigration, destination US city.\n",
    "    3. Dim_Demograhy - This table gives statistic information like percentage of female and male population, percentage of foreign born.\n",
    "    4. Dim_City This table consists of US City, State, State Code information.\n",
    "\n",
    "\n",
    "- Fact table is created by joining dimension tables.\n",
    "\n",
    "   - Fact_Immigration - \n",
    "   \n",
    "       This table gives information about immigration in US. It consists of information about year of immigration, origin country of immigration, destination city, destination state, temperature of destination city, population information and number of people immigrated from each origin country to US City each month of the year.\n",
    "\n",
    "\n",
    "- Star schema is chosen because of its simplicity and it is understandable for business people.  \n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "   1. Data is gathered from various source files.\n",
    "   2. Data cleansing steps are performed.\n",
    "   3. Dimension tables from source data are created.\n",
    "   4. Fact table is created by joining dimension tables.\n",
    "   5. Data in fact table is written into Parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating temporary views for dimension tables\n",
    "\n",
    "# Dim_Temperature\n",
    "df_temperature_city.createOrReplaceTempView(\"Dim_Temperature\")\n",
    "\n",
    "# Dim_Immigration\n",
    "df_Immigration_table.createOrReplaceTempView(\"Dim_Immigration\")\n",
    "\n",
    "# Dim_Demograhy\n",
    "df_demographic_info.createOrReplaceTempView(\"Dim_Demograhy\")\n",
    "\n",
    "# Dim_City\n",
    "df_city.createOrReplaceTempView(\"Dim_City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creation of Fact Tables by joining dimension tables\n",
    "\n",
    "df_ft_immigration = spark.sql(\"\"\"\n",
    "select\n",
    "              di.year as year_of_immigration\n",
    "             ,di.month as month_of_immigration\n",
    "             ,di.origin_country\n",
    "             ,dc.us_state as destination_state\n",
    "             ,di.destination_us_city as destination_city\n",
    "             ,dt.AverageTemperature as Avg_temp_city\n",
    "             ,dd.percent_foreigners\n",
    "             ,dd.natives\n",
    "             ,dd.Asian\n",
    "             ,dd.Black\n",
    "             ,dd.hispanic_or_latino\n",
    "             ,dd.White\n",
    "             ,count(di.destination_us_city) as count_immi_per_city\n",
    " from \n",
    "                 Dim_Immigration di\n",
    "      inner join Dim_Temperature dt \n",
    "              on lower(di.destination_us_city) = lower(dt.temp_city) and\n",
    "                 di.month = dt.month\n",
    "      inner join Dim_Demograhy dd\n",
    "              on lower(di.destination_us_city) = lower(dd.city)\n",
    "      inner join Dim_City dc\n",
    "              on lower(di.destination_us_city) = lower(dc.us_city)\n",
    "        group by\n",
    "              di.year\n",
    "             ,di.month \n",
    "             ,di.origin_country\n",
    "             ,dc.us_state\n",
    "             ,di.destination_us_city\n",
    "             ,dt.AverageTemperature\n",
    "             ,dd.percent_foreigners\n",
    "             ,dd.natives\n",
    "             ,dd.Asian\n",
    "             ,dd.Black\n",
    "             ,dd.hispanic_or_latino\n",
    "             ,dd.White\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fact_Immigration  \n",
    "df_ft_immigration.createOrReplaceTempView(\"Fact_Immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write data from fact table into parquet file\n",
    "df_ft_immigration.write.mode(\"append\").partitionBy(\"year_of_immigration\").parquet(\"output/Fact_Immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "# Below function checks if source or target dataframes has data\n",
    "def check_rows(df, info_of_dataframe):\n",
    "    '''\n",
    "    Input: Spark dataframe, information aout spark dataframe\n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    \n",
    "    check_data = df.count()\n",
    "    if check_data == 0:\n",
    "        print(\"Quality check failed for {}.\".format(info_of_dataframe))\n",
    "    else:\n",
    "        print(\"Quality check passed for {}\".format(info_of_dataframe, check_data))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check passed for Source : Temperature Data\n",
      "Quality check passed for Source : Demographic information Data\n",
      "Quality check passed for Source : Immigration Data\n",
      "Quality check passed for Source : i94port_valid data\n",
      "Quality check passed for Source : i94cit_valid data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source Data quality check\n",
    "check_rows(df_temp, \"Source : Temperature Data\")\n",
    "check_rows(df_us_city_demo, \"Source : Demographic information Data\")\n",
    "check_rows(Immigration_table, \"Source : Immigration Data\")\n",
    "check_rows(df_i94port_valid, \"Source : i94port_valid data\")\n",
    "check_rows(df_i94cit_valid, \"Source : i94cit_valid data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check passed for Target : Dim_Temperature\n",
      "Quality check passed for Target : Dim_City\n",
      "Quality check passed for Target : Dim_Immigration\n",
      "Quality check passed for Target : Dim_Demography\n",
      "Quality check passed for Target : Fact_Immigration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Dtaa Quality Check\n",
    "check_rows(df_temperature_city, \"Target : Dim_Temperature\")\n",
    "check_rows(df_city, \"Target : Dim_City\")\n",
    "check_rows(df_Immigration_table, \"Target : Dim_Immigration\")\n",
    "check_rows(df_demographic_info, \"Target : Dim_Demography\")\n",
    "check_rows(df_ft_immigration, \"Target : Fact_Immigration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "### Data Dictionary of Facts and dimension tables\n",
    "\n",
    "#### Temperature information per City - Dim_Temperature\n",
    "\n",
    "- year: integer (nullable = true) - Temperature Year\n",
    "- month: integer (nullable = true) - Temperture Month\n",
    "- AverageTemperature: double (nullable = true) - Average Temperature per city\n",
    "- temp_city: string (nullable = true) - Name of City\n",
    "- country: string (nullable = true) - Name of Country (Only United States)\n",
    "\n",
    "\n",
    "#### Immigration information per City - Dim_Immigration\n",
    "- cicid: double (nullable = true) - ID of person who was immigrated\n",
    "- year: integer (nullable = true) - Year of immigration\n",
    "- month: integer (nullable = true) -  Month of immigration\n",
    "- origin_country: string (nullable = true) - Country of origin\n",
    "- destination_port_code: string (nullable = true) -  String - 3 character port code of Destination\n",
    "- destination_us_city: string (nullable = true) - Name of destination city\n",
    "\n",
    "\n",
    "#### Demograpic information per City - Dim_Demograhy\n",
    "- City: string (nullable = true) - Name of US City\n",
    "- median_age: float (nullable = true) - Median Age per city\n",
    "- percent_Male_Population: double (nullable = true) - Percentage of Male population in total population\n",
    "- percent_Female_Population: double (nullable = true) - Percentage of Female population in total population\n",
    "- percent_veterans: double (nullable = true) - Percentage of veterans population in total population\n",
    "- percent_foreigners: double (nullable = true) - Percentage of foreigners population in total population\n",
    "- natives: double (nullable = true) - Percentage of Native Americans in total population\n",
    "- Asian: double (nullable = true) - Percentage of Asians in total population\n",
    "- Black: double (nullable = true) -Percentage of Black population in total population\n",
    "- hispanic_or_latino: double (nullable = true) - Percentage of hispanic or latino population in total population\n",
    "- White: double (nullable = true) - Percentage of white population in total population\n",
    "\n",
    "\n",
    "#### Demograpic information per City - Dim_City\n",
    "- us_state_code: string (nullable = true) - 2 Character code for each state in US\n",
    "- us_state: string (nullable = true) - Name of State in US\n",
    "- us_city: string (nullable = true) - Name of City in US\n",
    "\n",
    "\n",
    "#### Information about Immigration trend per City - Fact_Immigration\n",
    "- year_of_immigration: integer (nullable = true) - Year from dimension table Dim_Immigration\n",
    "- month_of_immigration: integer (nullable = true) - Month from dimension table Dim_Immigration\n",
    "- origin_country: string (nullable = true) -Country of origin from dimension table Dim_Immigration\n",
    "- destination_state: string (nullable = true) -US State from dimension table Dim_City\n",
    "- destination_city: string (nullable = true) - US City from dimension table Dim_Immigration\n",
    "- Avg_temp_city: double (nullable = true) - Average temperature per city from dimension table Dim_Temperature\n",
    "- percent_foreigners: double (nullable = true) - Percentage of foreigners in total population Dim_Demograhy\n",
    "- natives: double (nullable = true) - Percentage of native amreicans in total population Dim_Demograhy\n",
    "- Asian: double (nullable = true) - Percentage of Asians in total population Dim_Demograhy\n",
    "- Black: double (nullable = true) - Percentage of Black in total population Dim_Demograhy\n",
    "- hispanic_or_latino: double (nullable = true) - Percentage of hispanic or latino in total population Dim_Demograhy\n",
    "- White: double (nullable = true) - Percentage of white in total population Dim_Demograhy\n",
    "- count_immi_per_city: long (nullable = false) -Count of immigration per city per month and year from origin country\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* ##### Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  1. Spark can handle multiple file formats with large amount of data.\n",
    "  2. It is possible to extract data from multiple files into dataframes with the help of Spark.\n",
    "  3. With pyspark, data can be transformed into one or more tables as desired.\n",
    "\n",
    "* ##### Propose how often the data should be updated and why.\n",
    "  - Data should be updated monthly. The fact table gives information about immigration trend per city for each month. So It is necessary to update data on monthly basis.\n",
    "\n",
    "* ##### Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * ##### The data was increased by 100x.\n",
    "    - Below reasons makes Redshift as good fit.\n",
    "       1. Redshift has Massively Parallel Processing (MPP) which allows to load data at fast speed.\n",
    "       2. High performance\n",
    "       3. Scalibilty\n",
    " * ##### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "   - To update data on a daily basis at particular time, Airflow can be used.\n",
    " * ##### The database needed to be accessed by 100+ people.\n",
    "   - Redshift can be used since it has good read performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
